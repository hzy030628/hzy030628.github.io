---
uuid: 8cfa2256-e257-fe46-4179-a2f38d0bee98
title: 渗透流程简要记录--信息搜集
date: 2022-04-12 15:47:59
tags:
     - 渗透
categories:
     - 渗透认知
---

**渗透流程简要记录**--信息搜集
<!--more-->

在这里记录一下渗透的流程！

对网站进行渗透并不是想的这么简单，相反，复杂又困难！在这里把对渗透的理解说一下吧！

渗透刚开始需要的是信息搜集，搜集的宽度决定渗透的深度，这就话说的很对

# 信息搜集

对于渗透刚开始肯定只是拿到一个主站域名，这个时候我们该如何信息搜集，**子域名**，**c段**，开放端口这些都少不了。对于信息搜集我推荐一些方法，可以用[钟馗之眼](https://www.zoomeye.org)，[fofa](https://fofa.info/)，但是这俩个免费版的信息基本都被别人翻烂了，所以不充钱几乎没用，最好用的还是**谷歌**，使用谷歌语法可以搜集到很多有用的信息。

>
> Google语法
>
> site:"edu.cn"
>
> 最基本的edu的网站后缀。
>
> inurl:login|admin|manage|member|admin_login|login_admin|system|login|user|main|cms
>
> 查找文本内容：
>
> site:域名 intext:管理|后台|登陆|用户名|密码|验证码|系统|帐号|admin|login|sys|managetem|password|username
>
> 查找可注入点：site:域名 inurl:aspx|jsp|php|asp
>
> 查找上传漏洞：site:域名 inurl:file|load|editor|Files
>
> 找eweb编辑器：
>
> site:域名 inurl:ewebeditor|editor|uploadfile|eweb|edit
>
> 存在的数据库：site:域名 filetype:mdb|asp|#
>
> 查看脚本类型：site:域名 filetype:asp/aspx/php/jsp
>
> 迂回策略入侵：inurl:cms/data/templates/images/index/

当然对于**子域名的的搜集**可以使用在线平台，**ip138**这个可以用，不错

**扫目录**的话推荐使用**dirsearch**，这个工具在kali里面自带，，当然也可以在GitHub里面找

其次就是**c段探测活机**，这里推荐nmap，这里需要说一下一些常用的语法

> 111.111.111.111，对于这个ip，第一个111就是a段，第二个就是b段，第三个就是c段，第四个d段，若我们需要扫c段，可以
>
> namp 111.111.0.111/24
>
> 当然如果我们要扫描开放的端口可以直接nmap 111.11.111.11
>
> 深入学习可以看这个[map常用操作](https://hzy2003628.top/2022/04/11/nmap/)

在这里再介绍一下火狐和谷歌都可以使用的一个插件，**Shodan**这个插件可以直接看到网站的ip地址以及开放的端口，毕竟是个插件，哟时候会有误报的可能，但是使用这个插件可以看出网站端口是否套了cf，避免收集无用的c段（CF，全称cloudflare，一个CDN服务商，给网站套CF可以隐藏VPS IP、控制网站访问速度、设置防御规则等）

![](https://img-blog.csdnimg.cn/img_convert/5f8e5b0b8cd5e54676d3fa6a1e60a875.png)

**C段收集**方法：Shodan + Fofa。通过google-hacking找到合适目标后，利用Shodan判断出IP，再使用Fofa查看C段。
Fofa的语法是：ip=“192.168.1.0/24”，作用是将Fofa扫描过的C段列出来。在线网站终归是网站有时会更新不及时，但很适合走马观花般快速挖掘SRC。

> 注意灵活修改返回包，可以绕过一些登录的验证和密码找回，这个我在上一篇文章里面提到了，可以去看

翻阅网上的大佬写的博客无意间看到了一个脚本，感觉以后应该用得上，贴一下

未授权登录也是一些平台的漏洞，收集这些域名进行批量未授权登录也是一个偷懒挖洞的方法

```python
import requests
file = open('edu.txt','r')
number = file.readlines()
for i in number:
  i = i.rstrip()
  i = str(i)
  try:
    url = 'http://' + i + "paylaod"
    r = requests.get(url, timeout=1)
    r.encoding = r.apparent_encoding
    HtmlText = r.text
    if '0day' in HtmlText:
      print(url)
    else:
      pass
  except:
    pass
```

再推荐一个插件是**wappalyzer**，用这个插件可以直接看出来网站的框架是什么，比较方便，是谷歌插件，自行下载吧！

![image-20220412161123555](https://img-blog.csdnimg.cn/img_convert/24739cc372e2dcb7a0e2a72e93b86d9f.png)

关于信息搜集基本也就是这些，总之就是多搜集关键信息，之后就是找漏洞了！

推荐一个信息搜集思路，挺全的

[如何做到更加细致的信息搜集(上) (qq.com)](https://mp.weixin.qq.com/s/dkmr-Zq7M6G5rKmWQUBLPw)

[如何做到更加细致的信息搜集(下) (qq.com)](https://mp.weixin.qq.com/s?__biz=MzkxOTM1MTU0OQ==&mid=2247483709&idx=1&sn=7f3a53f08ae9498bc8a58a72427693ef&chksm=c1a238aff6d5b1b9040627626788bb591cc61b6beef0d209a9449919de7ad8b1bfde29e25ea4&scene=178&cur_album_id=2370471803288207363#rd)
